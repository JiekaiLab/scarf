{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA and ATAC Data Preprocessing Notebook\n",
    "This notebook provides a complete pipeline for preprocessing single-cell RNA-seq and ATAC-seq data, including normalization, filtering, and tokenization for downstream analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['hg38', 'mm10']\n",
    "species2token = {'hg38': 0, 'mm10': 1} \n",
    "dict_data_dir = './preprocess/dict_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_raw_names_all=['pbmc10k']\n",
    "species_=['hg38']\n",
    "rna_raw_names_all = [\n",
    "    \"sample_data/hPBMC_10k_scGLUE_10xDemo/gex.h5ad\"\n",
    "]\n",
    "\n",
    "atac_raw_names_all = [\n",
    "    \"sample_data/hPBMC_10k_scGLUE_10xDemo/atac.h5ad\"\n",
    "]\n",
    "\n",
    "# Define output directory\n",
    "output_dir = \"./processed_data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA Data Processing and Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_filter_based_ENSid(ENSG2token: Dict[str, str], ENSG_list: List[str]) -> List[str]:\n",
    "    '''\n",
    "    Filter genes based on ENSEMBL ID to token mapping.\n",
    "    Genes not in the mapping are marked as 'delete'.\n",
    "    '''\n",
    "    res = []\n",
    "    for ENSG in ENSG_list:\n",
    "        res.append(ENSG if ENSG in ENSG2token else \"delete\")\n",
    "    return res\n",
    "\n",
    "def Normalization_with_median(adata: anndata.AnnData, ENSid2median: Dict[str, int]) -> anndata.AnnData:\n",
    "    '''\n",
    "    Normalize expression data using gene-specific median values.\n",
    "    '''\n",
    "    if isinstance(adata.X, np.ndarray):\n",
    "        X = adata.X\n",
    "    else:\n",
    "        X = adata.X.toarray()\n",
    "\n",
    "    # Get median values for each gene\n",
    "    gene_nonzero_median = []\n",
    "    for gene_ENSid in adata.var.gene_ids.to_list():\n",
    "        gene_nonzero_median.append(ENSid2median.get(gene_ENSid, np.nan))\n",
    "    gene_nonzero_median = np.array(gene_nonzero_median)\n",
    "\n",
    "    # Normalize by median values\n",
    "    adata.X = np.nan_to_num(X / np.tile(gene_nonzero_median, (X.shape[0], 1)))\n",
    "    return adata\n",
    "\n",
    "def rank_rna_value(adata: anndata.AnnData, ENSG2token: Dict[str, int], species='hg38') -> Dict:\n",
    "    '''\n",
    "    Process RNA data: remove zeros, sort in descending order, and convert ENSEMBL IDs to tokens.\n",
    "    '''\n",
    "    ENSid_list = adata.var.index.to_list()\n",
    "    cell_names = adata.obs.index.to_list()\n",
    "    cell2data = {}\n",
    "    \n",
    "    \n",
    "    for cell_idx, cell_data in enumerate(tqdm(adata.X)):\n",
    "        # Get non-zero genes and sort in descending order\n",
    "        nonzero_mask = np.nonzero(cell_data)[0]\n",
    "        sorted_descend_indices = np.argsort(-cell_data[nonzero_mask])\n",
    "        value = cell_data[nonzero_mask][sorted_descend_indices]\n",
    "        ENSid_list_ = np.array(ENSid_list)[nonzero_mask][sorted_descend_indices]\n",
    "        \n",
    "        # Convert ENSEMBL IDs to tokens\n",
    "        id_list = list(itemgetter(*ENSid_list_)(ENSG2token))\n",
    "        assert len(id_list) == len(value)\n",
    "        \n",
    "        cell_name = cell_names[cell_idx]\n",
    "        cell2data[cell_name] = {\n",
    "            'input_ids': np.array(id_list).astype(np.int32),\n",
    "            'values': np.array(value).astype(np.float32),\n",
    "            'length': len(id_list),\n",
    "            'species': species2token[species],\n",
    "        }\n",
    "        \n",
    "        # Add cell type and batch information if available\n",
    "        if 'cell_type' in adata.obs.keys():\n",
    "            cell2data[cell_name]['cell_types'] = adata.obs.cell_type[cell_name]\n",
    "        if 'batch' in adata.obs.keys():\n",
    "            cell2data[cell_name]['batchs'] = adata.obs.batch[cell_name]\n",
    "            \n",
    "    return cell2data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATAC Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_filter_based_name(peak2token: Dict[str, str], peak_name_list: List[str], species=None) -> List[str]:\n",
    "    '''\n",
    "    Filter peaks based on name to token mapping.\n",
    "    Peaks not in the mapping are marked as 'delete'.\n",
    "    '''\n",
    "    \n",
    "    res = []\n",
    "    for peak_name in peak_name_list:\n",
    "        res.append(f\"{species}_{peak_name}\" if f\"{species}_{peak_name}\" in peak2token else \"delete\")\n",
    "    return res\n",
    "\n",
    "def rank_atac_peaks(adata: anndata.AnnData, peak2token: Dict[str, int], species) -> Dict:\n",
    "    '''\n",
    "    Process ATAC data: remove zeros and convert peak names to tokens.\n",
    "    '''\n",
    "    peak_name_list = [i for i in adata.var.index.to_list()]\n",
    "    peak_token_list = list(itemgetter(*peak_name_list)(peak2token))\n",
    "    cell_names = adata.obs.index.to_list()\n",
    "    cell2data = {}\n",
    "    \n",
    "    if isinstance(adata.X, np.ndarray):\n",
    "        X = adata.X\n",
    "    else:\n",
    "        X = adata.X.toarray()\n",
    "    \n",
    "    for cell_idx, cell_data in enumerate(tqdm(X)):\n",
    "        nonzero_mask = np.nonzero(cell_data)[0]\n",
    "        peak_token_list_cell = np.array(peak_token_list)[nonzero_mask]\n",
    "        cell_name = cell_names[cell_idx]\n",
    "        cell2data[cell_name] = peak_token_list_cell\n",
    "\n",
    "    return cell2data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(path: str, dataset: Dataset, rna_length: List[int], atac_length: List[int]) -> None:\n",
    "    '''save dataset to path, ascending sort length and save as pickle'''\n",
    "    dataset.save_to_disk(path)\n",
    "    sorted_list = sorted(rna_length)\n",
    "    with open(path + '/sorted_rna_length.pickle', 'wb') as f:\n",
    "        pickle.dump(sorted_list, f)\n",
    "    sorted_list = sorted(atac_length)\n",
    "    with open(path + '/sorted_atac_length.pickle', 'wb') as f:\n",
    "        pickle.dump(sorted_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample: pbmc10k\n",
      "1. Loading ENSG2token dictionary\n",
      "2. Loading median expression dictionary\n",
      "3. Loading data\n",
      "4. Filtering genes\n",
      "5. Normalizing and processing RNA data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/share/t_lgl/scFM/shared/Final_models_250514/SCARF/conda_scarf/lib/python3.12/site-packages/scanpy/preprocessing/_normalization.py:208: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "100%|██████████| 9631/9631 [00:33<00:00, 291.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Loading peak dictionaries\n",
      "7. Filtering and processing ATAC peaks\n",
      "8. Ranking ATAC peaks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9631/9631 [11:57<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. Loading ENSG2peakNum dictionary\n",
      "10. Processing multi-omics cells\n",
      "Sample pbmc10k has 9631 multi-omics cells\n",
      "Processed cell number: 100\n",
      "Processed cell number: 200\n",
      "Processed cell number: 300\n",
      "Processed cell number: 400\n",
      "Processed cell number: 500\n",
      "Processed cell number: 600\n",
      "Processed cell number: 700\n",
      "Processed cell number: 800\n",
      "Processed cell number: 900\n",
      "Processed cell number: 1000\n",
      "Processed cell number: 1100\n",
      "Processed cell number: 1200\n",
      "Processed cell number: 1300\n",
      "Processed cell number: 1400\n",
      "Processed cell number: 1500\n",
      "Processed cell number: 1600\n",
      "Processed cell number: 1700\n",
      "Processed cell number: 1800\n",
      "Processed cell number: 1900\n",
      "Processed cell number: 2000\n",
      "Processed cell number: 2100\n",
      "Processed cell number: 2200\n",
      "Processed cell number: 2300\n",
      "Processed cell number: 2400\n",
      "Processed cell number: 2500\n",
      "Processed cell number: 2600\n",
      "Processed cell number: 2700\n",
      "Processed cell number: 2800\n",
      "Processed cell number: 2900\n",
      "Processed cell number: 3000\n",
      "Processed cell number: 3100\n",
      "Processed cell number: 3200\n",
      "Processed cell number: 3300\n",
      "Processed cell number: 3400\n",
      "Processed cell number: 3500\n",
      "Processed cell number: 3600\n",
      "Processed cell number: 3700\n",
      "Processed cell number: 3800\n",
      "Processed cell number: 3900\n",
      "Processed cell number: 4000\n",
      "Processed cell number: 4100\n",
      "Processed cell number: 4200\n",
      "Processed cell number: 4300\n",
      "Processed cell number: 4400\n",
      "Processed cell number: 4500\n",
      "Processed cell number: 4600\n",
      "Processed cell number: 4700\n",
      "Processed cell number: 4800\n",
      "Processed cell number: 4900\n",
      "Processed cell number: 5000\n",
      "Processed cell number: 5100\n",
      "Processed cell number: 5200\n",
      "Processed cell number: 5300\n",
      "Processed cell number: 5400\n",
      "Processed cell number: 5500\n",
      "Processed cell number: 5600\n",
      "Processed cell number: 5700\n",
      "Processed cell number: 5800\n",
      "Processed cell number: 5900\n",
      "Processed cell number: 6000\n",
      "Processed cell number: 6100\n",
      "Processed cell number: 6200\n",
      "Processed cell number: 6300\n",
      "Processed cell number: 6400\n",
      "Processed cell number: 6500\n",
      "Processed cell number: 6600\n",
      "Processed cell number: 6700\n",
      "Processed cell number: 6800\n",
      "Processed cell number: 6900\n",
      "Processed cell number: 7000\n",
      "Processed cell number: 7100\n",
      "Processed cell number: 7200\n",
      "Processed cell number: 7300\n",
      "Processed cell number: 7400\n",
      "Processed cell number: 7500\n",
      "Processed cell number: 7600\n",
      "Processed cell number: 7700\n",
      "Processed cell number: 7800\n",
      "Processed cell number: 7900\n",
      "Processed cell number: 8000\n",
      "Processed cell number: 8100\n",
      "Processed cell number: 8200\n",
      "Processed cell number: 8300\n",
      "Processed cell number: 8400\n",
      "Processed cell number: 8500\n",
      "Processed cell number: 8600\n",
      "Processed cell number: 8700\n",
      "Processed cell number: 8800\n",
      "Processed cell number: 8900\n",
      "Processed cell number: 9000\n",
      "Processed cell number: 9100\n",
      "Processed cell number: 9200\n",
      "Processed cell number: 9300\n",
      "Processed cell number: 9400\n",
      "Processed cell number: 9500\n",
      "Processed cell number: 9600\n",
      "Sample pbmc10k: 9631 cells processed successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cdc2b3d4d943e5b20f85971ac2237f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/10 shards):   0%|          | 0/9631 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing for sample: pbmc10k\n"
     ]
    }
   ],
   "source": [
    "def process(each_cell_name):\n",
    "    \"\"\"\n",
    "    Process multi-omics data for a single cell.\n",
    "    \n",
    "    Args:\n",
    "        each_cell_name: Identifier for the cell to process\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing processed RNA and ATAC data for the cell\n",
    "    \"\"\"\n",
    "    # Extract RNA and ATAC data for the current cell\n",
    "    rna_data = rna_cell2data[each_cell_name]\n",
    "    atac_data = atac_cell2data[each_cell_name]\n",
    "    peak_num = len(atac_data)\n",
    "    \n",
    "    # Filter cells with insufficient ATAC data\n",
    "    if len(atac_data) < 1000:\n",
    "        return []\n",
    "\n",
    "    # Extract RNA features\n",
    "    rna_gene_ids = rna_data['input_ids']\n",
    "    rna_gene_values = rna_data['values']\n",
    "    rna_length = rna_data['length']\n",
    "    cell_type = rna_data['cell_types'] if 'cell_types' in rna_data else None\n",
    "\n",
    "    # Filter cells with insufficient RNA data\n",
    "    if rna_length < 50:\n",
    "        return []\n",
    "\n",
    "    # Map ATAC peaks to genes\n",
    "    gene_pos = []\n",
    "    for peak_id in atac_data:\n",
    "        if peak_id in peak2gene:\n",
    "            gene_pos.extend(peak2gene[peak_id])\n",
    "    gene_pos = np.array(gene_pos)\n",
    "\n",
    "    # Calculate ATAC gene accessibility scores\n",
    "    geneId2count = Counter(gene_pos[:, 0])\n",
    "    geneId_counts = np.array([[gene_id, count] for gene_id, count in geneId2count.items()])\n",
    "    geneId_total_peaks = np.array([ENSG2peakNum[token2ENSG[gene_token]] for gene_token in geneId_counts[:, 0]])\n",
    "    geneId_score = geneId_counts[:, 1] / geneId_total_peaks\n",
    "    \n",
    "    # Filter genes by accessibility score and select top ones\n",
    "    geneId_counts = geneId_counts[geneId_score > 0.01]\n",
    "    geneId_score = geneId_score[geneId_score > 0.01]\n",
    "    arg_sort_score = np.argsort(-geneId_score)\n",
    "    geneId_score = geneId_score[arg_sort_score]\n",
    "    geneId_counts = geneId_counts[arg_sort_score]\n",
    "    \n",
    "    if geneId_counts.shape[0] == 0:\n",
    "        return []\n",
    "\n",
    "    # Find intersection between RNA and ATAC genes\n",
    "    atac_genes_list = geneId_counts[:, 0].tolist()\n",
    "    ran_gene_list = rna_gene_ids.tolist()\n",
    "    gene_intersection = list(set(atac_genes_list) & set(ran_gene_list))\n",
    "    geneId_has_atac_ratio = len(gene_intersection) / len(ran_gene_list)\n",
    "\n",
    "    # Filter gene positions based on ATAC genes\n",
    "    id_indexs = np.isin(gene_pos[:, 0], atac_genes_list)\n",
    "    gene_pos = gene_pos[id_indexs]\n",
    "\n",
    "    # Organize peak-gene relationships\n",
    "    atac_length = geneId_counts.shape[0]\n",
    "    gene_peak = {}\n",
    "    unique_genes = geneId_counts[:, 0]\n",
    "    poses_list = [gene_pos[gene_pos[:, 0] == gene_id][:, 1].tolist() for gene_id in unique_genes]\n",
    "    lengths = [len(poses) for poses in poses_list]\n",
    "    count = np.cumsum([0] + lengths).tolist()\n",
    "    index = [pos for poses in poses_list for pos in poses]\n",
    "    gene_peak['count'] = count\n",
    "    gene_peak['index'] = index\n",
    "\n",
    "    # Extract batch information if available\n",
    "    batch = rna_data['batchs'] if 'batchs' in rna_data else None\n",
    "\n",
    "    # Return all processed data\n",
    "    return (np.array(rna_gene_ids).tolist(),\n",
    "            np.array(rna_gene_values).tolist(),\n",
    "            rna_length,\n",
    "            geneId_counts[:, 0],\n",
    "            geneId_score,\n",
    "            gene_peak,\n",
    "            atac_length,\n",
    "            geneId_has_atac_ratio,\n",
    "            peak_num,\n",
    "            each_cell_name,\n",
    "            atac_data,\n",
    "            cell_type,\n",
    "            batch)\n",
    "\n",
    "for sample_raw_name,species, sample_file_name_rna,sample_file_name_atac in zip(sample_raw_names_all, species_, rna_raw_names_all,atac_raw_names_all):\n",
    "\n",
    "    save_path = './processed_data/' + (sample_raw_name) + '/RNA_ATAC_data_v1'\n",
    "    print('Processing sample:', sample_raw_name)\n",
    "    \n",
    "    # 1. Load ENSG to token dictionary\n",
    "    print(\"1. Loading ENSG2token dictionary\")\n",
    "    ENSG2token_path = f'{dict_data_dir}/hm_ENSG2token_dict.pickle'\n",
    "    ENSG2token = pd.read_pickle(ENSG2token_path)\n",
    "    token2ENSG = {j: i for i, j in ENSG2token.items()}\n",
    "    \n",
    "    # 2. Load median expression values\n",
    "    print(\"2. Loading median expression dictionary\")\n",
    "    ENSG2median_path = f'{dict_data_dir}/RNA_nonzero_median_10W.{species}.pickle'\n",
    "    ENSG2median = pd.read_pickle(ENSG2median_path)\n",
    "    \n",
    "    # 3. Load RNA and ATAC data\n",
    "    print(\"3. Loading data\")\n",
    "    adata_rna_ = sc.read(sample_file_name_rna)\n",
    "        \n",
    "    adata_rna = anndata.AnnData(X=adata_rna_.X, var=adata_rna_.var, obs=adata_rna_.obs)\n",
    "    adata_atac = sc.read(sample_file_name_atac)\n",
    "    \n",
    "    # 4. Filter genes based on ENSG IDs\n",
    "    print(\"4. Filtering genes\")\n",
    "    gene_ENSid_list = gene_filter_based_ENSid(ENSG2token, adata_rna.var.index.to_list())\n",
    "    adata_rna.var['gene_names'] = adata_rna.var.gene_symbols\n",
    "    adata_rna.var.index = gene_ENSid_list\n",
    "    adata_rna = adata_rna[:, adata_rna.var.index != \"delete\"]\n",
    "    \n",
    "    # 5. Normalize and process RNA data\n",
    "    print(\"5. Normalizing and processing RNA data\")\n",
    "    sc.pp.normalize_total(adata_rna, target_sum=1e4, inplace=True)\n",
    "    sc.pp.log1p(adata_rna)\n",
    "    adata_rna = Normalization_with_median(adata_rna, ENSG2median)\n",
    "    rna_cell2data = rank_rna_value(adata_rna, ENSG2token, species=species)\n",
    "    \n",
    "    # 6. Load peak dictionaries\n",
    "    print(\"6. Loading peak dictionaries\")\n",
    "    peak2token_path = f'{dict_data_dir}/peak2token_dict.pickle'\n",
    "    peak2token = pd.read_pickle(peak2token_path)\n",
    "    peak2gene_path = f'{dict_data_dir}/peakId2geneID_dict.pickle'\n",
    "    peak2gene = pd.read_pickle(peak2gene_path)\n",
    "    \n",
    "    # 7-8. Filter and process ATAC peaks\n",
    "    print(\"7. Filtering and processing ATAC peaks\")\n",
    "    peak_name_list = peak_filter_based_name(peak2token, adata_atac.var.index.to_list(), species=species)\n",
    "    adata_atac.var.index = peak_name_list\n",
    "    adata_atac = adata_atac[:, adata_atac.var.index != \"delete\"]\n",
    "    \n",
    "    print(\"8. Ranking ATAC peaks\")\n",
    "    atac_cell2data = rank_atac_peaks(adata_atac, peak2token, species=species)\n",
    "    \n",
    "    # 9. Load ENSG to peak number dictionary\n",
    "    print(\"9. Loading ENSG2peakNum dictionary\")\n",
    "    ENSG2peakNum_path = f'{dict_data_dir}/ENSG2peakNum_dict.pickle'\n",
    "    ENSG2peakNum = pd.read_pickle(ENSG2peakNum_path)\n",
    "    \n",
    "    # 10. Process cells with both RNA and ATAC data\n",
    "    print(\"10. Processing multi-omics cells\")\n",
    "    rna_cell_names = list(rna_cell2data.keys())\n",
    "    atac_cell_names = list(atac_cell2data.keys())\n",
    "    cell_inter_names = sorted(list(set(rna_cell_names) & set(atac_cell_names)))\n",
    "    \n",
    "    print(f\"Sample {sample_raw_name} has {len(cell_inter_names)} multi-omics cells\")\n",
    "    \n",
    "    # Initialize lists to store processed data\n",
    "    rna_gene_ids = []\n",
    "    rna_gene_values = []\n",
    "    atac_gene_peaks = []\n",
    "    rna_lengths = []\n",
    "    cell_names = []\n",
    "    gene_id_has_atac_ratios = []\n",
    "    peak_nums = []\n",
    "    atac_gene_ids = []\n",
    "    atac_gene_scores = []\n",
    "    atac_lengths = []\n",
    "    atac_cell_peaks = []\n",
    "    cell_types = []\n",
    "    batchs = []\n",
    "    \n",
    "    # Process cells in parallel\n",
    "    pool = multiprocessing.Pool(processes=2)\n",
    "    results = pool.imap(process, cell_inter_names)\n",
    "    \n",
    "    for res in results:\n",
    "        if len(res) > 1:\n",
    "            rna_gene_ids.append(res[0])\n",
    "            rna_gene_values.append(res[1])\n",
    "            rna_lengths.append(res[2])\n",
    "            atac_gene_ids.append(res[3])\n",
    "            atac_gene_scores.append(res[4])\n",
    "            atac_gene_peaks.append(res[5])\n",
    "            atac_lengths.append(res[6])\n",
    "            gene_id_has_atac_ratios.append(res[7])\n",
    "            peak_nums.append(res[8])\n",
    "            cell_names.append(res[9])\n",
    "            atac_cell_peaks.append(res[10])\n",
    "            cell_types.append(res[11])\n",
    "            batchs.append(res[12])\n",
    "\n",
    "        if len(atac_lengths) > 0 and len(atac_lengths) % 100 == 0:\n",
    "            print(f\"Processed cell number: {len(atac_lengths)}\")\n",
    "\n",
    "    print(f\"Sample {sample_raw_name}: {len(atac_lengths)} cells processed successfully\")\n",
    "    \n",
    "    # 11. Create dataset dictionary\n",
    "    data_dict = {\n",
    "        'rna_gene_ids': rna_gene_ids,\n",
    "        'rna_gene_values': rna_gene_values,\n",
    "        'rna_lengths': rna_lengths,\n",
    "        'atac_gene_ids': atac_gene_ids,\n",
    "        'atac_gene_scores': atac_gene_scores,\n",
    "        'atac_gene_peaks': atac_gene_peaks,\n",
    "        'atac_cell_peaks': atac_cell_peaks,\n",
    "        'atac_lengths': atac_lengths,\n",
    "        'genes_has_atac': gene_id_has_atac_ratios,\n",
    "        'peak_num': peak_nums,\n",
    "        'species': [species2token[species]] * len(atac_lengths),\n",
    "        'cell_name': cell_names,\n",
    "        'cell_types': cell_types,\n",
    "    }\n",
    "\n",
    "    # Add batch information if available\n",
    "    if None not in batchs:\n",
    "        data_dict['batchs'] = batchs\n",
    "        structure = Features({\n",
    "            'rna_gene_ids': Sequence(feature=Value(dtype='int32')),\n",
    "            'rna_gene_values': Sequence(feature=Value(dtype='float32')),\n",
    "            'rna_lengths': Value(dtype='int16'),\n",
    "            'atac_gene_ids': Sequence(feature=Value(dtype='int32')),\n",
    "            'atac_gene_scores': Sequence(feature=Value(dtype='float16')),\n",
    "            'atac_gene_peaks': {\n",
    "                'count': Sequence(feature=Value(dtype='int32')),\n",
    "                'index': Sequence(feature=Value(dtype='int16'))\n",
    "            },\n",
    "            'atac_cell_peaks': Sequence(feature=Value(dtype='int32')),\n",
    "            'atac_lengths': Value(dtype='int16'),\n",
    "            'genes_has_atac': Value(dtype='float16'),\n",
    "            'peak_num': Value(dtype='int32'),\n",
    "            'species': Value(dtype='int8'),\n",
    "            'cell_name': Value(dtype='string'),\n",
    "            'cell_types': Value(dtype='string'),\n",
    "            'batchs': Value(dtype='string'),\n",
    "        })\n",
    "    else:\n",
    "        structure = Features({\n",
    "            'rna_gene_ids': Sequence(feature=Value(dtype='int32')),\n",
    "            'rna_gene_values': Sequence(feature=Value(dtype='float32')),\n",
    "            'rna_lengths': Value(dtype='int16'),\n",
    "            'atac_gene_ids': Sequence(feature=Value(dtype='int32')),\n",
    "            'atac_gene_scores': Sequence(feature=Value(dtype='float16')),\n",
    "            'atac_gene_peaks': {\n",
    "                'count': Sequence(feature=Value(dtype='int32')),\n",
    "                'index': Sequence(feature=Value(dtype='int16'))\n",
    "            },\n",
    "            'atac_cell_peaks': Sequence(feature=Value(dtype='int32')),\n",
    "            'atac_lengths': Value(dtype='int16'),\n",
    "            'genes_has_atac': Value(dtype='float16'),\n",
    "            'peak_num': Value(dtype='int32'),\n",
    "            'species': Value(dtype='int8'),\n",
    "            'cell_name': Value(dtype='string'),\n",
    "            'cell_types': Value(dtype='string'),\n",
    "        })\n",
    "\n",
    "    # 12. Create and save dataset\n",
    "    dataset = Dataset.from_dict(data_dict, features=structure)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_data(save_path, dataset, rna_lengths, atac_lengths)\n",
    "\n",
    "    # Clean up\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    del data_dict\n",
    "    print(f\"Completed processing for sample: {sample_raw_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
