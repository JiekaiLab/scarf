{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA and ATAC Data Preprocessing Notebook\n",
    "This notebook provides a complete pipeline for preprocessing single-cell RNA-seq and ATAC-seq data, including normalization, filtering, and tokenization for downstream analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from datasets import Dataset, Features, Sequence, Value\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rna_raw_names_all = [\n",
    "    \"/public/share/t_lgl/scFM/evaluation/data_set/raw_data/09_hPBMC_10k_scGLUE_10xDemo/gex.h5ad\"\n",
    "]\n",
    "\n",
    "atac_raw_names_all = [\n",
    "    \"/public/share/t_lgl/scFM/evaluation/data_set/raw_data/09_hPBMC_10k_scGLUE_10xDemo/atac.h5ad\"\n",
    "]\n",
    "\n",
    "# Define output directory\n",
    "output_dir = \"./processed_data/\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Filtering Based on ENSEMBL IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_filter_based_ENSid(ENSG2token: Dict[str, str], ENSG_list: List[str]) -> List[str]:\n",
    "    '''\n",
    "    Filter genes based on ENSEMBL ID to token mapping.\n",
    "    Genes not in the mapping are marked as 'delete'.\n",
    "    '''\n",
    "    res = []\n",
    "    for ENSG in ENSG_list:\n",
    "        res.append(ENSG if ENSG in ENSG2token else \"delete\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization with Gene Median Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization_with_median(adata: anndata.AnnData, ENSid2median: Dict[str, int]) -> anndata.AnnData:\n",
    "    '''\n",
    "    Normalize expression data using gene-specific median values.\n",
    "    '''\n",
    "    if isinstance(adata.X, np.ndarray):\n",
    "        X = adata.X\n",
    "    else:\n",
    "        X = adata.X.toarray()\n",
    "\n",
    "    # Get median values for each gene\n",
    "    gene_nonzero_median = []\n",
    "    for gene_ENSid in adata.var.gene_ids.to_list():\n",
    "        gene_nonzero_median.append(ENSid2median.get(gene_ENSid, np.nan))\n",
    "    gene_nonzero_median = np.array(gene_nonzero_median)\n",
    "\n",
    "    # Normalize by median values\n",
    "    adata.X = np.nan_to_num(X / np.tile(gene_nonzero_median, (X.shape[0], 1)))\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNA Data Processing and Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank_rna_value(adata: anndata.AnnData, ENSG2token: Dict[str, int], species='hg38') -> Dict:\n",
    "    '''\n",
    "    Process RNA data: remove zeros, sort in descending order, and convert ENSEMBL IDs to tokens.\n",
    "    '''\n",
    "    ENSid_list = adata.var.index.to_list()\n",
    "    cell_names = adata.obs.index.to_list()\n",
    "    cell2data = {}\n",
    "    \n",
    "    species2token = {'hg38': 0, 'mm10': 1}  # Example mapping\n",
    "    \n",
    "    for cell_idx, cell_data in enumerate(tqdm(adata.X)):\n",
    "        # Get non-zero genes and sort in descending order\n",
    "        nonzero_mask = np.nonzero(cell_data)[0]\n",
    "        sorted_descend_indices = np.argsort(-cell_data[nonzero_mask])\n",
    "        value = cell_data[nonzero_mask][sorted_descend_indices]\n",
    "        ENSid_list_ = np.array(ENSid_list)[nonzero_mask][sorted_descend_indices]\n",
    "        \n",
    "        # Convert ENSEMBL IDs to tokens\n",
    "        id_list = list(itemgetter(*ENSid_list_)(ENSG2token))\n",
    "        assert len(id_list) == len(value)\n",
    "        \n",
    "        cell_name = cell_names[cell_idx]\n",
    "        cell2data[cell_name] = {\n",
    "            'input_ids': np.array(id_list).astype(np.int32),\n",
    "            'values': np.array(value).astype(np.float32),\n",
    "            'length': len(id_list),\n",
    "            'species': species2token[species],\n",
    "        }\n",
    "        \n",
    "        # Add cell type and batch information if available\n",
    "        if 'cell_type' in adata.obs.keys():\n",
    "            cell2data[cell_name]['cell_types'] = adata.obs.cell_type[cell_name]\n",
    "        if 'batch' in adata.obs.keys():\n",
    "            cell2data[cell_name]['batchs'] = adata.obs.batch[cell_name]\n",
    "            \n",
    "    return cell2data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATAC Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def peak_filter_based_name(peak2token: Dict[str, str], peak_name_list: List[str], species=None) -> List[str]:\n",
    "    '''\n",
    "    Filter peaks based on name to token mapping.\n",
    "    Peaks not in the mapping are marked as 'delete'.\n",
    "    '''\n",
    "    res = []\n",
    "    for peak_name in peak_name_list:\n",
    "        res.append(f\"{species}_{peak_name}\" if f\"{species}_{peak_name}\" in peak2token else \"delete\")\n",
    "    return res\n",
    "\n",
    "def rank_atac_peaks(adata: anndata.AnnData, peak2token: Dict[str, int], species) -> Dict:\n",
    "    '''\n",
    "    Process ATAC data: remove zeros and convert peak names to tokens.\n",
    "    '''\n",
    "    peak_name_list = [i for i in adata.var.index.to_list()]\n",
    "    peak_token_list = list(itemgetter(*peak_name_list)(peak2token))\n",
    "    cell_names = adata.obs.index.to_list()\n",
    "    cell2data = {}\n",
    "    \n",
    "    if isinstance(adata.X, np.ndarray):\n",
    "        X = adata.X\n",
    "    else:\n",
    "        X = adata.X.toarray()\n",
    "    \n",
    "    for cell_idx, cell_data in enumerate(tqdm(X)):\n",
    "        nonzero_mask = np.nonzero(cell_data)[0]\n",
    "        peak_token_list_cell = np.array(peak_token_list)[nonzero_mask]\n",
    "        cell_name = cell_names[cell_idx]\n",
    "        cell2data[cell_name] = peak_token_list_cell\n",
    "\n",
    "    return cell2data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading ENSG2token dictionary\n",
      "2. Loading median value dictionary\n",
      "**************************************************\n",
      "Processing: gex\n",
      "**************************************************\n",
      "3. Loading data\n",
      "/public/share/t_lgl/scFM/evaluation/data_set/raw_data/09_hPBMC_10k_scGLUE_10xDemo/gex.h5ad\n",
      "4. Filtering genes\n",
      "5. Normalizing, filtering, and ranking RNA values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/share/t_lgl/scFM/shared/Final_models_250514/SCARF/conda_scarf/lib/python3.12/site-packages/scanpy/preprocessing/_normalization.py:208: UserWarning: Received a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9631, 19365)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9631/9631 [00:40<00:00, 238.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Processing individual cells\n",
      "gex, 9631 cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Creating dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8121e5fbd0433594a64ed9ca383432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9631 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete for gex. Data saved to ./processed_data/gex/RNA_ATAC_data_v1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_data(path: str, dataset: Dataset, rna_length: List[int]) -> None:\n",
    "    '''\n",
    "    Save processed dataset to disk with sorted RNA lengths.\n",
    "    '''\n",
    "    dataset.save_to_disk(path)\n",
    "    sorted_list = sorted(rna_length)\n",
    "    with open(os.path.join(path, 'sorted_rna_length.pickle'), 'wb') as f:\n",
    "        pickle.dump(sorted_list, f)\n",
    "\n",
    "def process(each_cell_name):\n",
    "    '''\n",
    "    Process individual cells by extracting RNA and ATAC information.\n",
    "    '''\n",
    "    rna_data = rna_cell2data[each_cell_name]\n",
    "    \n",
    "    # Extract RNA data\n",
    "    rna_gene_ids = rna_data['input_ids']\n",
    "    rna_gene_values = rna_data['values']\n",
    "    rna_length = rna_data['length']\n",
    "    cell_type = rna_data['cell_types'] if 'cell_types' in rna_data else None\n",
    "    batch = rna_data['batchs'] if 'batchs' in rna_data else None\n",
    "\n",
    "    return (np.array(rna_gene_ids).tolist(),\n",
    "            np.array(rna_gene_values).tolist(),\n",
    "            rna_length, \n",
    "            each_cell_name,\n",
    "            cell_type,\n",
    "            batch)\n",
    "\n",
    "\n",
    "# Define species and corresponding token\n",
    "species_ = [\"hg38\"]\n",
    "species2token = {j: i for i, j in enumerate(species_)}\n",
    "\n",
    "# Define paths to dictionary files\n",
    "dict_data_dir = '../prior_data'\n",
    "\n",
    "# Load ENSG to token mapping\n",
    "print(\"1. Loading ENSG2token dictionary\")\n",
    "ENSG2token_path = f'{dict_data_dir}/hm_ENSG2token_dict.pickle'\n",
    "ENSG2token = pd.read_pickle(ENSG2token_path)\n",
    "token2ENSG = {j: i for i, j in ENSG2token.items()}\n",
    "\n",
    "# Load gene median values\n",
    "print(\"2. Loading median value dictionary\")\n",
    "ENSG2median_path = f'{dict_data_dir}/RNA_nonzero_median_10W.hg38.pickle'\n",
    "ENSG2median = pd.read_pickle(ENSG2median_path)\n",
    "\n",
    "# Process each sample\n",
    "for species, sample_file_name_rna in zip(species_, rna_raw_names_all):\n",
    "    sample_raw_name = os.path.basename(sample_file_name_rna).split(\".\")[0]\n",
    "    save_path = os.path.join(output_dir, sample_raw_name, 'RNA_ATAC_data_v1')\n",
    "    \n",
    "    print('*' * 50)\n",
    "    print(f'Processing: {sample_raw_name}')\n",
    "    print('*' * 50)\n",
    "    \n",
    "    # Load RNA data\n",
    "    print(\"3. Loading data\")\n",
    "    print(sample_file_name_rna)\n",
    "    adata_rna_ = sc.read(sample_file_name_rna)\n",
    "    adata_rna = anndata.AnnData(X=adata_rna_.X, var=adata_rna_.var, obs=adata_rna_.obs)\n",
    "    \n",
    "    # Filter genes based on ENSEMBL IDs\n",
    "    print(\"4. Filtering genes\")\n",
    "    adata_rna.var['gene_ids'] = adata_rna.var['gene_ids'].str.replace(r'\\.\\d+$', '', regex=True)\n",
    "    gene_ENSid_list = gene_filter_based_ENSid(ENSG2token, adata_rna.var.gene_ids.to_list())\n",
    "    adata_rna.var['gene_names'] = adata_rna.var.index.tolist()\n",
    "    adata_rna.var.index = gene_ENSid_list\n",
    "    adata_rna = adata_rna[:, adata_rna.var.index != \"delete\"]\n",
    "    \n",
    "    # Normalize and process RNA data\n",
    "    print(\"5. Normalizing, filtering, and ranking RNA values\")\n",
    "    sc.pp.normalize_total(adata_rna, target_sum=1e4, inplace=True)\n",
    "    print(adata_rna.shape)\n",
    "    sc.pp.log1p(adata_rna)\n",
    "    adata_rna = Normalization_with_median(adata_rna, ENSG2median)\n",
    "    rna_cell2data = rank_rna_value(adata_rna, ENSG2token, species=species)\n",
    "    \n",
    "    # Process cells\n",
    "    print(\"6. Processing individual cells\")\n",
    "    rna_cell_names = list(rna_cell2data.keys())\n",
    "    cell_inter_names = sorted(rna_cell_names)\n",
    "    print(f\"{sample_raw_name}, {len(cell_inter_names)} cells\")\n",
    "    \n",
    "    # Prepare data arrays\n",
    "    rna_gene_ids = []\n",
    "    rna_gene_values = []\n",
    "    rna_lengths = []\n",
    "    cell_names = []\n",
    "    cell_types = []\n",
    "    batchs = []\n",
    "    \n",
    "    # Process cells in parallel\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        results = pool.imap(process, cell_inter_names)\n",
    "        for res in results:\n",
    "            if len(res) > 1:\n",
    "                rna_gene_ids.append(res[0])\n",
    "                rna_gene_values.append(res[1])\n",
    "                rna_lengths.append(res[2])\n",
    "                cell_names.append(res[3])\n",
    "                cell_types.append(res[4])\n",
    "                batchs.append(res[5])\n",
    "    \n",
    "    # Create dataset\n",
    "    print(\"7. Creating dataset\")\n",
    "    data_dict = {\n",
    "        'rna_gene_ids': rna_gene_ids,\n",
    "        'rna_gene_values': rna_gene_values,\n",
    "        'rna_lengths': rna_lengths,\n",
    "        'species': [species2token[species]] * len(rna_lengths),\n",
    "        'cell_name': cell_names,\n",
    "        'cell_types': cell_types,\n",
    "    }\n",
    "    \n",
    "    # Add batch information if available\n",
    "    if None not in batchs:\n",
    "        data_dict['batchs'] = batchs\n",
    "    \n",
    "    # Define dataset structure\n",
    "    structure = Features({\n",
    "        'rna_gene_ids': Sequence(feature=Value(dtype='int32')),\n",
    "        'rna_gene_values': Sequence(feature=Value(dtype='float32')),\n",
    "        'rna_lengths': Value(dtype='int16'),\n",
    "        'species': Value(dtype='int8'),\n",
    "        'cell_name': Value(dtype='string'),\n",
    "        'cell_types': Value(dtype='string'),\n",
    "    })\n",
    "    \n",
    "    # Add batch field if available\n",
    "    if None not in batchs:\n",
    "        structure = Features({\n",
    "            'rna_gene_ids': Sequence(feature=Value(dtype='int32')),\n",
    "            'rna_gene_values': Sequence(feature=Value(dtype='float32')),\n",
    "            'rna_lengths': Value(dtype='int16'),\n",
    "            'species': Value(dtype='int8'),\n",
    "            'cell_name': Value(dtype='string'),\n",
    "            'cell_types': Value(dtype='string'),\n",
    "            'batchs': Value(dtype='string'),\n",
    "        })\n",
    "    \n",
    "    # Create and save dataset\n",
    "    dataset = Dataset.from_dict(data_dict, features=structure)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_data(save_path, dataset, rna_lengths)\n",
    "    \n",
    "    print(f\"Processing complete for {sample_raw_name}. Data saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
